{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4089822,"sourceType":"kernelVersion"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, TimeDistributed, Flatten, LSTM, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\n\n# تعريف نموذج CNN-LSTM\ndef create_cnn_lstm_model(input_shape, num_classes):\n    model = Sequential()\n\n    # طبقات CNN\n    model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'), input_shape=input_shape))\n    model.add(TimeDistributed(BatchNormalization()))\n    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n    model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same')))\n    model.add(TimeDistributed(BatchNormalization()))\n    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n    model.add(TimeDistributed(Conv2D(128, (3, 3), activation='relu', padding='same')))\n    model.add(TimeDistributed(BatchNormalization()))\n    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n    model.add(TimeDistributed(Flatten()))\n\n    # طبقات LSTM\n    model.add(LSTM(128, return_sequences=True))\n    model.add(Dropout(0.5))\n    model.add(LSTM(64))\n    model.add(Dropout(0.5))\n\n    # طبقات Fully Connected\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n\n    # تجميع النموذج\n    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n    return model\n\n# تحضير البيانات (هذا مثال، يجب استبداله ببياناتك الخاصة)\ndef load_example_data():\n    # مثال: إنشاء بيانات وهمية\n    num_samples = 200  # عدد العينات\n    num_frames = 30    # عدد الإطارات في كل فيديو\n    height, width, channels = 64, 64, 3  # أبعاد الإطارات\n    num_classes = 10   # عدد الفئات (العلامات)\n\n    X_train = np.random.rand(num_samples, num_frames, height, width, channels)  # بيانات تدريب\n    y_train = np.random.randint(0, num_classes, num_samples)  # تسميات تدريب\n\n    X_test = np.random.rand(num_samples // 2, num_frames, height, width, channels)  # بيانات اختبار\n    y_test = np.random.randint(0, num_classes, num_samples // 2)  # تسميات اختبار\n\n    # تحويل التسميات إلى one-hot encoding\n    y_train = to_categorical(y_train, num_classes)\n    y_test = to_categorical(y_test, num_classes)\n\n    return X_train, X_test, y_train, y_test\n\n# تحميل البيانات\nX_train, X_test, y_train, y_test = load_example_data()\n\n# تعريف شكل المدخلات وعدد الفئات\ninput_shape = (None, 64, 64, 3)  # (عدد الإطارات, ارتفاع, عرض, قنوات)\nnum_classes = 10\n\n# إنشاء النموذج\nmodel = create_cnn_lstm_model(input_shape, num_classes)\n\n# تدريب النموذج\nhistory = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n\n# تقييم النموذج\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f'Test Loss: {loss}')\nprint(f'Test Accuracy: {accuracy}')\n\n# حفظ النموذج\nmodel.save('sign_language_cnn_lstm_v2.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T19:59:16.262008Z","iopub.execute_input":"2025-03-20T19:59:16.262401Z","iopub.status.idle":"2025-03-20T21:27:46.197922Z","shell.execute_reply.started":"2025-03-20T19:59:16.262369Z","shell.execute_reply":"2025-03-20T21:27:46.195622Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 37s/step - accuracy: 0.1220 - loss: 2.3503 - val_accuracy: 0.0800 - val_loss: 2.4199\nEpoch 2/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 39s/step - accuracy: 0.1575 - loss: 2.2954 - val_accuracy: 0.1400 - val_loss: 2.3018\nEpoch 3/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 37s/step - accuracy: 0.0957 - loss: 2.3176 - val_accuracy: 0.0800 - val_loss: 2.2826\nEpoch 4/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 36s/step - accuracy: 0.1017 - loss: 2.3338 - val_accuracy: 0.0800 - val_loss: 2.2836\nEpoch 5/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 39s/step - accuracy: 0.1112 - loss: 2.3695 - val_accuracy: 0.1500 - val_loss: 2.2849\nEpoch 6/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 35s/step - accuracy: 0.0856 - loss: 2.3475 - val_accuracy: 0.1500 - val_loss: 2.2951\nEpoch 7/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 39s/step - accuracy: 0.1176 - loss: 2.2951 - val_accuracy: 0.1500 - val_loss: 2.2947\nEpoch 8/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 36s/step - accuracy: 0.1322 - loss: 2.3011 - val_accuracy: 0.1500 - val_loss: 2.2927\nEpoch 9/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 36s/step - accuracy: 0.1627 - loss: 2.2901 - val_accuracy: 0.1500 - val_loss: 2.2875\nEpoch 10/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 36s/step - accuracy: 0.1270 - loss: 2.2985 - val_accuracy: 0.1500 - val_loss: 2.2860\nEpoch 11/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 36s/step - accuracy: 0.1654 - loss: 2.2764 - val_accuracy: 0.1500 - val_loss: 2.2875\nEpoch 12/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 39s/step - accuracy: 0.1302 - loss: 2.3028 - val_accuracy: 0.1500 - val_loss: 2.2891\nEpoch 13/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 35s/step - accuracy: 0.1390 - loss: 2.2630 - val_accuracy: 0.0800 - val_loss: 2.2927\nEpoch 14/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 38s/step - accuracy: 0.0649 - loss: 2.3165 - val_accuracy: 0.0800 - val_loss: 2.2917\nEpoch 15/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 35s/step - accuracy: 0.1203 - loss: 2.2828 - val_accuracy: 0.0500 - val_loss: 2.2901\nEpoch 16/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 35s/step - accuracy: 0.1076 - loss: 2.3169 - val_accuracy: 0.0800 - val_loss: 2.2914\nEpoch 17/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 39s/step - accuracy: 0.1137 - loss: 2.3066 - val_accuracy: 0.0800 - val_loss: 2.2969\nEpoch 18/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 35s/step - accuracy: 0.1079 - loss: 2.3181 - val_accuracy: 0.0800 - val_loss: 2.2979\nEpoch 19/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 39s/step - accuracy: 0.1283 - loss: 2.3174 - val_accuracy: 0.0800 - val_loss: 2.2972\nEpoch 20/20\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 35s/step - accuracy: 0.1042 - loss: 2.3111 - val_accuracy: 0.0800 - val_loss: 2.2975\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.0747 - loss: 2.3066\nTest Loss: 2.2975471019744873\nTest Accuracy: 0.07999999821186066\n","output_type":"stream"}],"execution_count":7}]}