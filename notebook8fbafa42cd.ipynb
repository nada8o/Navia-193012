{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":212544762,"sourceType":"kernelVersion"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-18T14:55:35.847284Z","iopub.status.idle":"2025-03-18T14:55:35.848004Z","shell.execute_reply":"2025-03-18T14:55:35.847724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, TimeDistributed, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Define paths\ndata_dir = '/kaggle/input/machine-learning-toolkits-awesome-ml-resources'  # تأكد من أن هذا المسار صحيح\n\n# تحقق من وجود المسار\nif not os.path.exists(data_dir):\n    raise FileNotFoundError(f\"Directory {data_dir} does not exist. Please check the path.\")\n\n# Hyperparameters\nimg_width, img_height = 64, 64\nbatch_size = 32  # حجم الدفعة\nepochs = 20\nnum_classes = 29  # اضبط بناءً على عدد فئات لغة الإشارة\ntimesteps = 10  # عدد الإطارات في كل تسلسل\n\n# Custom Data Generator for Sequences\ndef sequence_generator(directory, datagen, batch_size, timesteps, img_size, subset):\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=img_size,\n        batch_size=batch_size * timesteps,  # تحميل عدد كافٍ من الصور لإنشاء التسلسلات\n        class_mode='sparse',  # استخدام 'sparse' للحصول على تسميات عددية\n        subset=subset\n    )\n    while True:\n        x, y = generator.__next__()  # استخدام __next__() بدلاً من next()\n        \n        # حساب عدد الدفعات بناءً على عدد الصور المتاحة\n        num_samples = x.shape[0]\n        actual_batch_size = num_samples // timesteps\n        \n        # إعادة تشكيل البيانات\n        x = x[:actual_batch_size * timesteps]  # تأكد من أن عدد الصور قابل للقسمة على timesteps\n        x = x.reshape((actual_batch_size, timesteps, img_size[0], img_size[1], 3))  # إعادة تشكيل إلى (actual_batch_size, timesteps, height, width, channels)\n        \n        y = y[:actual_batch_size * timesteps]  # تأكد من أن عدد التسميات قابل للقسمة على timesteps\n        y = y[::timesteps]  # تحديد التسميات للتسلسلات\n        \n        # تحويل التسميات إلى one-hot encoding\n        y = to_categorical(y, num_classes=num_classes)\n        \n        yield x, y\n\n# Data preprocessing\ndatagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\n# Calculate the number of samples\ntrain_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size * timesteps,\n    class_mode='sparse',  # استخدام 'sparse' للحصول على تسميات عددية\n    subset='training'\n)\n\nvalidation_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size * timesteps,\n    class_mode='sparse',  # استخدام 'sparse' للحصول على تسميات عددية\n    subset='validation'\n)\n\n# Total number of training and validation samples\ntotal_train_samples = train_generator.samples\ntotal_val_samples = validation_generator.samples\n\n# Steps per epoch\nsteps_per_epoch = total_train_samples // (batch_size * timesteps)\nvalidation_steps = total_val_samples // (batch_size * timesteps)\n\n# Reinitialize the generators for training\ntrain_generator = sequence_generator(\n    data_dir,\n    datagen,\n    batch_size,\n    timesteps,\n    (img_width, img_height),\n    subset='training'\n)\n\nvalidation_generator = sequence_generator(\n    data_dir,\n    datagen,\n    batch_size,\n    timesteps,\n    (img_width, img_height),\n    subset='validation'\n)\n\n# CNN-LSTM Model\nmodel = Sequential()\n\n# CNN Part\nmodel.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=(timesteps, img_width, img_height, 3)))\nmodel.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\nmodel.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu')))\nmodel.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\nmodel.add(TimeDistributed(Conv2D(128, (3, 3), activation='relu')))\nmodel.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\nmodel.add(TimeDistributed(Flatten()))\n\n# LSTM Part\nmodel.add(LSTM(128, return_sequences=False))\nmodel.add(Dropout(0.5))\n\n# Fully Connected Layer\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Model Summary\nmodel.summary()\n\n# Train the model\nprint(\"Training the model...\")\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=steps_per_epoch,\n    validation_data=validation_generator,\n    validation_steps=validation_steps,\n    epochs=epochs\n)\n\n# Evaluate the model on the test data\nprint(\"Evaluating the model on the test data...\")\ntest_loss, test_accuracy = model.evaluate(validation_generator, steps=validation_steps)\nprint(f'Test Loss: {test_loss:.4f}')\nprint(f'Test Accuracy: {test_accuracy:.4f}')\n\n# Predict on the test data\nprint(\"Predicting on the test data...\")\ny_pred = model.predict(validation_generator, steps=validation_steps)\ny_pred_classes = np.argmax(y_pred, axis=1)\n\n# Get the true labels\ny_true = []\nfor i in range(validation_steps):\n    _, y = validation_generator.__next__()\n    y_true.extend(np.argmax(y, axis=1))\n\n# Classification Report\nprint(\"Classification Report:\")\nprint(classification_report(y_true, y_pred_classes))\n\n# Confusion Matrix\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_true, y_pred_classes))\n\n# Save the model\nmodel.save('sign_language_cnn_lstm_model.h5')\nprint(\"Model saved successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:41:52.419007Z","iopub.execute_input":"2025-03-23T21:41:52.419521Z"}},"outputs":[{"name":"stdout","text":"Found 0 images belonging to 0 classes.\nFound 0 images belonging to 0 classes.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_13\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ time_distributed_91                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m896\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ time_distributed_92                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ time_distributed_93                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │          \u001b[38;5;34m18,496\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ time_distributed_94                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ time_distributed_95                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │          \u001b[38;5;34m73,856\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ time_distributed_96                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ time_distributed_97                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m4608\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m2,425,344\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)                  │           \u001b[38;5;34m3,741\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ time_distributed_91                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ time_distributed_92                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ time_distributed_93                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ time_distributed_94                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ time_distributed_95                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ time_distributed_96                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ time_distributed_97                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,425,344</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,741</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,538,845\u001b[0m (9.68 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,538,845</span> (9.68 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,538,845\u001b[0m (9.68 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,538,845</span> (9.68 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Training the model...\nFound 0 images belonging to 0 classes.\nEpoch 1/20\n  16077/Unknown \u001b[1m503s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00","output_type":"stream"}],"execution_count":null}]}